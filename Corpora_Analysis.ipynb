{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CSE4022 \n",
        "\n",
        "NATURAL LANGUAGE PROCESSING\n",
        "\n",
        "DIGITAL ASSIGNMENT - 1\n",
        "\n",
        "Corpora Analysis and Text Processing using NLTK\n",
        "\n",
        "   - Keerthana S 20BCE1049"
      ],
      "metadata": {
        "id": "GDU6vMUefxj7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk3oprPnrX-h",
        "outputId": "f21b9049-35b6-4618-e641-fc6e5871b57a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import os\n",
        "import nltk\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Utilize Python NLTK (Natural Language Tool Kit) Platform and do the following. \n",
        "Install relevant Packages and Libraries\n",
        "\n",
        "• Explore Brown Corpus and find the size, tokens, categories,\n",
        "\n",
        "• Find the size of word tokens?\n",
        "\n",
        "• Find the size of word types?\n",
        "\n",
        "• Find the size of the category “government”\n",
        "\n",
        "• List the most frequent tokens\n",
        "\n",
        "• Count the number of sentences"
      ],
      "metadata": {
        "id": "vIhbHzv-fhV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('brown')\n",
        "from nltk.corpus import brown\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "metadata": {
        "id": "gjaU55VUt6Gt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb9f053f-27a6-4ae2-8c56-6633b8842c11"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "brown.raw()\n",
        "#Size\n",
        "print(\"Size of Brown corpus: \", len(brown.raw()))\n",
        "#Tokens\n",
        "w_tokens=nltk.word_tokenize(brown.raw())\n",
        "print(\"No of tokens: \",len(w_tokens))\n",
        "\n",
        "s_tokens=nltk.sent_tokenize(brown.raw())\n",
        "print(\"No of tokens: \",len(s_tokens))\n",
        "\n",
        "#Categories\n",
        "print(\"Categories:\",brown.categories())\n",
        "print(\"No of categories: \",len(brown.categories()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnn-77A-ubXN",
        "outputId": "5a11146e-4bde-453a-d80d-50000122ecac"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of Brown corpus:  9964284\n",
            "No of tokens:  1439319\n",
            "No of tokens:  60647\n",
            "Categories: ['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n",
            "No of categories:  15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "types=len(set(brown.words()))\n",
        "print(\"Size of word types:\", types)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJon7TJ9kPcs",
        "outputId": "f085ca61-5844-4879-a59a-d78841d93ba9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of word types: 56057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extrace paragraphs from the corpus \n",
        "paragraph = brown.paras()\n",
        "print(\"Total Paragraphs:\", len(paragraph))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO8FOgIeulwQ",
        "outputId": "400cd5a9-369e-44dd-a673-851321f38184"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Paragraphs: 15667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extract sentences from the corpus \n",
        "sentences = brown.sents()\n",
        "print(\"Total Sentences:\",len(sentences))\n",
        "print(\"First sentence:\",sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK-CTLXkuwRo",
        "outputId": "281a5a0a-0aa3-4b05-8535-1d67cd4dbcd3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sentences: 57340\n",
            "First sentence: ['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extract words from the corpos\n",
        "print(\"Words in the corpus:\",brown.words())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmnKPmnAuy9R",
        "outputId": "03605da1-c736-4e7e-fa44-ed7c6cb6f469"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words in the corpus: ['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq = nltk.FreqDist(brown.words())\n",
        "#common words \n",
        "print(\"Common Words:\", freq.most_common(10))\n",
        "#specific words \n",
        "print(\"Specific Word: \", len(brown.words(categories=['government'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-owEC2xJu4a3",
        "outputId": "ce0c6d7c-7422-4064-d62f-4846cb63e347"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common Words: [('the', 62713), (',', 58334), ('.', 49346), ('of', 36080), ('and', 27915), ('to', 25732), ('a', 21881), ('in', 19536), ('that', 10237), ('is', 10011)]\n",
            "Specific Word:  70117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Explore the corpora available in NLTK (any two) \n",
        "\n",
        "• Raw corpus\n",
        "• POS tagged \n",
        "• Parsed \n",
        "• Multilingual aligned\n",
        "• Spoken language\n",
        "• Semantic tagged"
      ],
      "metadata": {
        "id": "h6tYIVZSoXJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#POS Tagged Corpus\n",
        "print(brown.words())\n",
        "print(brown.tagged_words())\n",
        "print(brown.sents())\n",
        "print(brown.tagged_sents())\n",
        "print(brown.paras(categories='reviews'))\n",
        "print(brown.tagged_paras(categories='reviews'))\n",
        "\n",
        "nltk.download('indian')\n",
        "from nltk.corpus import indian\n",
        "print(indian.words()) \n",
        "print(indian.tagged_words()) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLao-UV2QWJE",
        "outputId": "eb3a57ab-9223-40d5-8906-acbd4617f8ea"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]\n",
            "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]\n",
            "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]\n",
            "[[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')], [('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('City', 'NN-TL'), ('of', 'IN-TL'), ('Atlanta', 'NP-TL'), (\"''\", \"''\"), ('for', 'IN'), ('the', 'AT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'AT'), ('election', 'NN'), ('was', 'BEDZ'), ('conducted', 'VBN'), ('.', '.')], ...]\n",
            "[[['It', 'is', 'not', 'news', 'that', 'Nathan', 'Milstein', 'is', 'a', 'wizard', 'of', 'the', 'violin', '.'], ['Certainly', 'not', 'in', 'Orchestra', 'Hall', 'where', 'he', 'has', 'played', 'countless', 'recitals', ',', 'and', 'where', 'Thursday', 'night', 'he', 'celebrated', 'his', '20th', 'season', 'with', 'the', 'Chicago', 'Symphony', 'Orchestra', ',', 'playing', 'the', 'Brahms', 'Concerto', 'with', 'his', 'own', 'slashing', ',', 'demon-ridden', 'cadenza', 'melting', 'into', 'the', 'high', ',', 'pale', ',', 'pure', 'and', 'lovely', 'song', 'with', 'which', 'a', 'violinist', 'unlocks', 'the', 'heart', 'of', 'the', 'music', ',', 'or', 'forever', 'finds', 'it', 'closed', '.']], [['There', 'was', 'about', 'that', 'song', 'something', 'incandescent', ',', 'for', 'this', 'Brahms', 'was', 'Milstein', 'at', 'white', 'heat', '.'], ['Not', 'the', 'noblest', 'performance', 'we', 'have', 'heard', 'him', 'play', ',', 'or', 'the', 'most', 'spacious', ',', 'or', 'even', 'the', 'most', 'eloquent', '.'], ['Those', 'would', 'be', 'reserved', 'for', 'the', \"orchestra's\", 'great', 'nights', 'when', 'the', 'soloist', 'can', 'surpass', 'himself', '.'], ['This', 'time', 'the', 'orchestra', 'gave', 'him', 'some', 'superb', 'support', 'fired', 'by', 'response', 'to', 'his', 'own', 'high', 'mood', '.'], ['But', 'he', 'had', 'in', 'Walter', 'Hendl', 'a', 'willing', 'conductor', 'able', 'only', 'up', 'to', 'a', 'point', '.']], ...]\n",
            "[[[('It', 'PPS'), ('is', 'BEZ'), ('not', '*'), ('news', 'NN'), ('that', 'CS'), ('Nathan', 'NP'), ('Milstein', 'NP'), ('is', 'BEZ'), ('a', 'AT'), ('wizard', 'NN'), ('of', 'IN'), ('the', 'AT'), ('violin', 'NN'), ('.', '.')], [('Certainly', 'RB'), ('not', '*'), ('in', 'IN'), ('Orchestra', 'NN-TL'), ('Hall', 'NN-TL'), ('where', 'WRB'), ('he', 'PPS'), ('has', 'HVZ'), ('played', 'VBN'), ('countless', 'JJ'), ('recitals', 'NNS'), (',', ','), ('and', 'CC'), ('where', 'WRB'), ('Thursday', 'NR'), ('night', 'NN'), ('he', 'PPS'), ('celebrated', 'VBD'), ('his', 'PP$'), ('20th', 'OD'), ('season', 'NN'), ('with', 'IN'), ('the', 'AT'), ('Chicago', 'NP-TL'), ('Symphony', 'NN-TL'), ('Orchestra', 'NN-TL'), (',', ','), ('playing', 'VBG'), ('the', 'AT'), ('Brahms', 'NP-TL'), ('Concerto', 'NN-TL'), ('with', 'IN'), ('his', 'PP$'), ('own', 'JJ'), ('slashing', 'VBG'), (',', ','), ('demon-ridden', 'JJ'), ('cadenza', 'NN'), ('melting', 'VBG'), ('into', 'IN'), ('the', 'AT'), ('high', 'JJ'), (',', ','), ('pale', 'JJ'), (',', ','), ('pure', 'JJ'), ('and', 'CC'), ('lovely', 'JJ'), ('song', 'NN'), ('with', 'IN'), ('which', 'WDT'), ('a', 'AT'), ('violinist', 'NN'), ('unlocks', 'VBZ'), ('the', 'AT'), ('heart', 'NN'), ('of', 'IN'), ('the', 'AT'), ('music', 'NN'), (',', ','), ('or', 'CC'), ('forever', 'RB'), ('finds', 'VBZ'), ('it', 'PPO'), ('closed', 'VBN'), ('.', '.')]], [[('There', 'EX'), ('was', 'BEDZ'), ('about', 'IN'), ('that', 'DT'), ('song', 'NN'), ('something', 'PN'), ('incandescent', 'JJ'), (',', ','), ('for', 'CS'), ('this', 'DT'), ('Brahms', 'NP'), ('was', 'BEDZ'), ('Milstein', 'NP'), ('at', 'IN'), ('white', 'JJ'), ('heat', 'NN'), ('.', '.')], [('Not', '*'), ('the', 'AT'), ('noblest', 'JJT'), ('performance', 'NN'), ('we', 'PPSS'), ('have', 'HV'), ('heard', 'VBN'), ('him', 'PPO'), ('play', 'VB'), (',', ','), ('or', 'CC'), ('the', 'AT'), ('most', 'QL'), ('spacious', 'JJ'), (',', ','), ('or', 'CC'), ('even', 'RB'), ('the', 'AT'), ('most', 'QL'), ('eloquent', 'JJ'), ('.', '.')], [('Those', 'DTS'), ('would', 'MD'), ('be', 'BE'), ('reserved', 'VBN'), ('for', 'IN'), ('the', 'AT'), (\"orchestra's\", 'NN$'), ('great', 'JJ'), ('nights', 'NNS'), ('when', 'WRB'), ('the', 'AT'), ('soloist', 'NN'), ('can', 'MD'), ('surpass', 'VB'), ('himself', 'PPL'), ('.', '.')], [('This', 'DT'), ('time', 'NN'), ('the', 'AT'), ('orchestra', 'NN'), ('gave', 'VBD'), ('him', 'PPO'), ('some', 'DTI'), ('superb', 'JJ'), ('support', 'NN'), ('fired', 'VBN'), ('by', 'IN'), ('response', 'NN'), ('to', 'IN'), ('his', 'PP$'), ('own', 'JJ'), ('high', 'JJ'), ('mood', 'NN'), ('.', '.')], [('But', 'CC'), ('he', 'PPS'), ('had', 'HVD'), ('in', 'IN'), ('Walter', 'NP'), ('Hendl', 'NP'), ('a', 'AT'), ('willing', 'JJ'), ('conductor', 'NN'), ('able', 'JJ'), ('only', 'RB'), ('up', 'IN'), ('to', 'IN'), ('a', 'AT'), ('point', 'NN'), ('.', '.')]], ...]\n",
            "['মহিষের', 'সন্তান', ':', 'তোড়া', 'উপজাতি', '৷', ...]\n",
            "[('মহিষের', 'NN'), ('সন্তান', 'NN'), (':', 'SYM'), ...]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/indian.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Parsed Corpora\n",
        "nltk.download('treebank')\n",
        "from nltk.corpus import treebank\n",
        "print(treebank.fileids())\n",
        "print(treebank.words('wsj_0003.mrg'))\n",
        "print(treebank.tagged_words('wsj_0003.mrg'))\n",
        "print(treebank.parsed_sents('wsj_0003.mrg')[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYKjiyHsUWLk",
        "outputId": "531d1108-82de-427a-caea-5a5b1df7d35d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['wsj_0001.mrg', 'wsj_0002.mrg', 'wsj_0003.mrg', 'wsj_0004.mrg', 'wsj_0005.mrg', 'wsj_0006.mrg', 'wsj_0007.mrg', 'wsj_0008.mrg', 'wsj_0009.mrg', 'wsj_0010.mrg', 'wsj_0011.mrg', 'wsj_0012.mrg', 'wsj_0013.mrg', 'wsj_0014.mrg', 'wsj_0015.mrg', 'wsj_0016.mrg', 'wsj_0017.mrg', 'wsj_0018.mrg', 'wsj_0019.mrg', 'wsj_0020.mrg', 'wsj_0021.mrg', 'wsj_0022.mrg', 'wsj_0023.mrg', 'wsj_0024.mrg', 'wsj_0025.mrg', 'wsj_0026.mrg', 'wsj_0027.mrg', 'wsj_0028.mrg', 'wsj_0029.mrg', 'wsj_0030.mrg', 'wsj_0031.mrg', 'wsj_0032.mrg', 'wsj_0033.mrg', 'wsj_0034.mrg', 'wsj_0035.mrg', 'wsj_0036.mrg', 'wsj_0037.mrg', 'wsj_0038.mrg', 'wsj_0039.mrg', 'wsj_0040.mrg', 'wsj_0041.mrg', 'wsj_0042.mrg', 'wsj_0043.mrg', 'wsj_0044.mrg', 'wsj_0045.mrg', 'wsj_0046.mrg', 'wsj_0047.mrg', 'wsj_0048.mrg', 'wsj_0049.mrg', 'wsj_0050.mrg', 'wsj_0051.mrg', 'wsj_0052.mrg', 'wsj_0053.mrg', 'wsj_0054.mrg', 'wsj_0055.mrg', 'wsj_0056.mrg', 'wsj_0057.mrg', 'wsj_0058.mrg', 'wsj_0059.mrg', 'wsj_0060.mrg', 'wsj_0061.mrg', 'wsj_0062.mrg', 'wsj_0063.mrg', 'wsj_0064.mrg', 'wsj_0065.mrg', 'wsj_0066.mrg', 'wsj_0067.mrg', 'wsj_0068.mrg', 'wsj_0069.mrg', 'wsj_0070.mrg', 'wsj_0071.mrg', 'wsj_0072.mrg', 'wsj_0073.mrg', 'wsj_0074.mrg', 'wsj_0075.mrg', 'wsj_0076.mrg', 'wsj_0077.mrg', 'wsj_0078.mrg', 'wsj_0079.mrg', 'wsj_0080.mrg', 'wsj_0081.mrg', 'wsj_0082.mrg', 'wsj_0083.mrg', 'wsj_0084.mrg', 'wsj_0085.mrg', 'wsj_0086.mrg', 'wsj_0087.mrg', 'wsj_0088.mrg', 'wsj_0089.mrg', 'wsj_0090.mrg', 'wsj_0091.mrg', 'wsj_0092.mrg', 'wsj_0093.mrg', 'wsj_0094.mrg', 'wsj_0095.mrg', 'wsj_0096.mrg', 'wsj_0097.mrg', 'wsj_0098.mrg', 'wsj_0099.mrg', 'wsj_0100.mrg', 'wsj_0101.mrg', 'wsj_0102.mrg', 'wsj_0103.mrg', 'wsj_0104.mrg', 'wsj_0105.mrg', 'wsj_0106.mrg', 'wsj_0107.mrg', 'wsj_0108.mrg', 'wsj_0109.mrg', 'wsj_0110.mrg', 'wsj_0111.mrg', 'wsj_0112.mrg', 'wsj_0113.mrg', 'wsj_0114.mrg', 'wsj_0115.mrg', 'wsj_0116.mrg', 'wsj_0117.mrg', 'wsj_0118.mrg', 'wsj_0119.mrg', 'wsj_0120.mrg', 'wsj_0121.mrg', 'wsj_0122.mrg', 'wsj_0123.mrg', 'wsj_0124.mrg', 'wsj_0125.mrg', 'wsj_0126.mrg', 'wsj_0127.mrg', 'wsj_0128.mrg', 'wsj_0129.mrg', 'wsj_0130.mrg', 'wsj_0131.mrg', 'wsj_0132.mrg', 'wsj_0133.mrg', 'wsj_0134.mrg', 'wsj_0135.mrg', 'wsj_0136.mrg', 'wsj_0137.mrg', 'wsj_0138.mrg', 'wsj_0139.mrg', 'wsj_0140.mrg', 'wsj_0141.mrg', 'wsj_0142.mrg', 'wsj_0143.mrg', 'wsj_0144.mrg', 'wsj_0145.mrg', 'wsj_0146.mrg', 'wsj_0147.mrg', 'wsj_0148.mrg', 'wsj_0149.mrg', 'wsj_0150.mrg', 'wsj_0151.mrg', 'wsj_0152.mrg', 'wsj_0153.mrg', 'wsj_0154.mrg', 'wsj_0155.mrg', 'wsj_0156.mrg', 'wsj_0157.mrg', 'wsj_0158.mrg', 'wsj_0159.mrg', 'wsj_0160.mrg', 'wsj_0161.mrg', 'wsj_0162.mrg', 'wsj_0163.mrg', 'wsj_0164.mrg', 'wsj_0165.mrg', 'wsj_0166.mrg', 'wsj_0167.mrg', 'wsj_0168.mrg', 'wsj_0169.mrg', 'wsj_0170.mrg', 'wsj_0171.mrg', 'wsj_0172.mrg', 'wsj_0173.mrg', 'wsj_0174.mrg', 'wsj_0175.mrg', 'wsj_0176.mrg', 'wsj_0177.mrg', 'wsj_0178.mrg', 'wsj_0179.mrg', 'wsj_0180.mrg', 'wsj_0181.mrg', 'wsj_0182.mrg', 'wsj_0183.mrg', 'wsj_0184.mrg', 'wsj_0185.mrg', 'wsj_0186.mrg', 'wsj_0187.mrg', 'wsj_0188.mrg', 'wsj_0189.mrg', 'wsj_0190.mrg', 'wsj_0191.mrg', 'wsj_0192.mrg', 'wsj_0193.mrg', 'wsj_0194.mrg', 'wsj_0195.mrg', 'wsj_0196.mrg', 'wsj_0197.mrg', 'wsj_0198.mrg', 'wsj_0199.mrg']\n",
            "['A', 'form', 'of', 'asbestos', 'once', 'used', '*', ...]\n",
            "[('A', 'DT'), ('form', 'NN'), ('of', 'IN'), ...]\n",
            "(S\n",
            "  (S-TPC-1\n",
            "    (NP-SBJ\n",
            "      (NP (NP (DT A) (NN form)) (PP (IN of) (NP (NN asbestos))))\n",
            "      (RRC\n",
            "        (ADVP-TMP (RB once))\n",
            "        (VP\n",
            "          (VBN used)\n",
            "          (NP (-NONE- *))\n",
            "          (S-CLR\n",
            "            (NP-SBJ (-NONE- *))\n",
            "            (VP\n",
            "              (TO to)\n",
            "              (VP\n",
            "                (VB make)\n",
            "                (NP (NNP Kent) (NN cigarette) (NNS filters))))))))\n",
            "    (VP\n",
            "      (VBZ has)\n",
            "      (VP\n",
            "        (VBN caused)\n",
            "        (NP\n",
            "          (NP (DT a) (JJ high) (NN percentage))\n",
            "          (PP (IN of) (NP (NN cancer) (NNS deaths)))\n",
            "          (PP-LOC\n",
            "            (IN among)\n",
            "            (NP\n",
            "              (NP (DT a) (NN group))\n",
            "              (PP\n",
            "                (IN of)\n",
            "                (NP\n",
            "                  (NP (NNS workers))\n",
            "                  (RRC\n",
            "                    (VP\n",
            "                      (VBN exposed)\n",
            "                      (NP (-NONE- *))\n",
            "                      (PP-CLR (TO to) (NP (PRP it)))\n",
            "                      (ADVP-TMP\n",
            "                        (NP\n",
            "                          (QP (RBR more) (IN than) (CD 30))\n",
            "                          (NNS years))\n",
            "                        (IN ago))))))))))))\n",
            "  (, ,)\n",
            "  (NP-SBJ (NNS researchers))\n",
            "  (VP (VBD reported) (SBAR (-NONE- 0) (S (-NONE- *T*-1))))\n",
            "  (. .))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Semantic Tagged\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import wordnet as wn\n",
        "wn.synsets('motorcar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUMyGhserjqH",
        "outputId": "0bde0988-6fbe-4150-f2fd-9c782e3c228b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('car.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('car.n.01').lemma_names()\n",
        "wn.synset('car.n.01').definition()\n",
        "wn.synset('car.n.01').examples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHSJ0-r1sHZd",
        "outputId": "12b457f7-4eee-4837-f57c-27a40c85ec80"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['he needs a car to get to work']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synsets('car')\n",
        "for synset in wn.synsets('car'):\n",
        "  print(synset.lemma_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0xTpkJqsVay",
        "outputId": "bf929b04-3d60-4b39-8bad-9eae39072fa4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['car', 'auto', 'automobile', 'machine', 'motorcar']\n",
            "['car', 'railcar', 'railway_car', 'railroad_car']\n",
            "['car', 'gondola']\n",
            "['car', 'elevator_car']\n",
            "['cable_car', 'car']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Create a text corpus with a minimum of 200 words (unique content). Implement the \n",
        "following text processing \n",
        "\n",
        "• Word segmentation\n",
        "• Sentence segmentation\n",
        "• Convert to Lowercase\n",
        "• Stop words removal\n",
        "• Stemming\n",
        "• Lemmatization\n",
        "• Part of speech tagger"
      ],
      "metadata": {
        "id": "8Iej9wraojEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
        "\n",
        "filecontent1 = \"\"\"Hello There! This is Keerthana here!\\nTopic is Programming using Python\\n\n",
        "      Python is a high level language which is converted to low level using an interpreter.\\n\n",
        "      There are many built-in functions and packges to implement any idea through program. Also, there are frameworks like Django to create web applications using python.\\n\n",
        "      Python is also being used in Data Science field for Machine Learning, Image Processing and Natural Language Processing.  Python is a dynamically types and garbage collecting language.\n",
        "      It supports multiple programming paradigms like object oriented, functional and structured programming.\"\"\"\n",
        "filecontent2 = \"\"\"Next topic is Programming using C++\\n\n",
        "      C++ is also a high level structured language. C++ is an object oriented language which means that it follows the OOPs concepts of data abstraction, encapsulation, modularity, inheritance and polymorphism.\\n\n",
        "      C++ also supports the concept of pointers. Java, is similar to C++ but avoid the issue of dreaded diamond caused by multiple inheritance in C++. So, multiple inheritance is possible only in C++.\n",
        "      C++ is influenced by C. But the main difference arises in the OOPs concept of inheritance as C doesn't support inheritance.\"\"\"\n",
        "\n",
        "corpusdir = 'nltk_data/'\n",
        "if not os.path.isdir(corpusdir):\n",
        "    os.mkdir(corpusdir)\n",
        "with open(corpusdir + 'content1.txt', 'w') as text_file:\n",
        "    text_file.write(filecontent1)\n",
        "with open(corpusdir + 'content2.txt', 'w') as text_file:\n",
        "    text_file.write(filecontent2)\n",
        "\n",
        "text_corpus = PlaintextCorpusReader(corpusdir, [\"content1.txt\", \"content2.txt\"])\n",
        "#Word Segmentation\n",
        "words = text_corpus.words()\n",
        "print(\"Words in the corpus: \",words)\n",
        "print(\"Total no of words in the corpus: \", len(words))\n",
        "print(\"Unique words in the corpus: \", len(set(words)))\n",
        "\n",
        "no_of_words_corpus1 = len(text_corpus.words(\"content1.txt\"))\n",
        "print(\"No of words in file 1: \", no_of_words_corpus1)\n",
        "no_of_unique_words_corpus1 = len(set(text_corpus.words(\"content1.txt\")))\n",
        "print(\"No of unique words in the file 1: \",no_of_unique_words_corpus1)\n",
        "\n",
        "no_of_words_corpus2 = len(text_corpus.words(\"content2.txt\"))\n",
        "print(\"No of words in file 2: \", no_of_words_corpus2)\n",
        "no_of_unique_words_corpus2 = len(set(text_corpus.words(\"content2.txt\")))\n",
        "print(\"No of unique words in file 2: \", no_of_unique_words_corpus2)\n",
        "\n",
        "#Sentence Segmentation\n",
        "sentence = text_corpus.sents()\n",
        "print(\"Senetences: \", sentence)\n",
        "print(\"No of sentences: \", len(sentence))\n",
        "\n",
        "#Converting to lower case\n",
        "print(\"Conversion to lower case: \")\n",
        "txt = \"\"\n",
        "for i in words:\n",
        "  print(i.lower(), end=\" \")\n",
        "  txt += (i.lower()+\" \")\n",
        "\n",
        "#Stop words removal\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "print(\"\\nStop word removal: \")\n",
        "tokenized = sent_tokenize(txt)\n",
        "for i in tokenized:\n",
        "\t# Word tokenizers is used to find the words\n",
        "\t# and punctuation in a string\n",
        "  wordsList = nltk.word_tokenize(i)\n",
        "\n",
        "  # removing stop words from wordList\n",
        "  stop_words = set(stopwords.words(\"english\"))\n",
        "  wordsList = [w for w in wordsList if not w in stop_words]\n",
        "  print(wordsList)\n",
        "\n",
        "#Stemming\n",
        "print(\"\\nStemming: \")\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "# choose some words to be stemmed\n",
        "\n",
        "for w in words:\n",
        "\tprint(w, \" : \", ps.stem(w))\n",
        "\n",
        "\n",
        "#Lemmatization\n",
        "\n",
        "print(\"\\nLemmatization: \")\n",
        "# import these modules\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "for w in words:\n",
        "  print(w, \": \", lemmatizer.lemmatize(w))\n",
        "\n",
        "\n",
        "#Part of speech tagger\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "print(\"\\nPOS tagger: \")\n",
        "tokenized = sent_tokenize(txt)\n",
        "for i in tokenized:\n",
        "\t\n",
        "\t# Word tokenizers is used to find the words\n",
        "\t# and punctuation in a string\n",
        "  wordsList = nltk.word_tokenize(i)\n",
        "\n",
        "\t# removing stop words from wordList\n",
        "  stop_words = set(stopwords.words(\"english\"))\n",
        "  wordsList = [w for w in wordsList if not w in stop_words]\n",
        "\n",
        "\t# Using a Tagger. Which is part-of-speech\n",
        "\t# tagger or POS-tagger.\n",
        "  tagged = nltk.pos_tag(wordsList)\n",
        "\n",
        "  print(tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FweNcWFvrCg",
        "outputId": "dd951621-f209-4a9d-83af-f9c1b9d40fb3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words in the corpus:  ['Hello', 'There', '!', 'This', 'is', 'Keerthana', ...]\n",
            "Total no of words in the corpus:  213\n",
            "Unique words in the corpus:  114\n",
            "No of words in file 1:  103\n",
            "No of unique words in the file 1:  71\n",
            "No of words in file 2:  110\n",
            "No of unique words in file 2:  63\n",
            "Senetences:  [['Hello', 'There', '!'], ['This', 'is', 'Keerthana', 'here', '!'], ...]\n",
            "No of sentences:  16\n",
            "Conversion to lower case: \n",
            "hello there ! this is keerthana here ! topic is programming using python python is a high level language which is converted to low level using an interpreter . there are many built - in functions and packges to implement any idea through program . also , there are frameworks like django to create web applications using python . python is also being used in data science field for machine learning , image processing and natural language processing . python is a dynamically types and garbage collecting language . it supports multiple programming paradigms like object oriented , functional and structured programming . next topic is programming using c ++ c ++ is also a high level structured language . c ++ is an object oriented language which means that it follows the oops concepts of data abstraction , encapsulation , modularity , inheritance and polymorphism . c ++ also supports the concept of pointers . java , is similar to c ++ but avoid the issue of dreaded diamond caused by multiple inheritance in c ++. so , multiple inheritance is possible only in c ++. c ++ is influenced by c . but the main difference arises in the oops concept of inheritance as c doesn ' t support inheritance . \n",
            "Stop word removal: \n",
            "['hello', '!']\n",
            "['keerthana', '!']\n",
            "['topic', 'programming', 'using', 'python', 'python', 'high', 'level', 'language', 'converted', 'low', 'level', 'using', 'interpreter', '.']\n",
            "['many', 'built', '-', 'functions', 'packges', 'implement', 'idea', 'program', '.']\n",
            "['also', ',', 'frameworks', 'like', 'django', 'create', 'web', 'applications', 'using', 'python', '.']\n",
            "['python', 'also', 'used', 'data', 'science', 'field', 'machine', 'learning', ',', 'image', 'processing', 'natural', 'language', 'processing', '.']\n",
            "['python', 'dynamically', 'types', 'garbage', 'collecting', 'language', '.']\n",
            "['supports', 'multiple', 'programming', 'paradigms', 'like', 'object', 'oriented', ',', 'functional', 'structured', 'programming', '.']\n",
            "['next', 'topic', 'programming', 'using', 'c', '++', 'c', '++', 'also', 'high', 'level', 'structured', 'language', '.']\n",
            "['c', '++', 'object', 'oriented', 'language', 'means', 'follows', 'oops', 'concepts', 'data', 'abstraction', ',', 'encapsulation', ',', 'modularity', ',', 'inheritance', 'polymorphism', '.']\n",
            "['c', '++', 'also', 'supports', 'concept', 'pointers', '.']\n",
            "['java', ',', 'similar', 'c', '++', 'avoid', 'issue', 'dreaded', 'diamond', 'caused', 'multiple', 'inheritance', 'c', '++', '.']\n",
            "[',', 'multiple', 'inheritance', 'possible', 'c', '++', '.']\n",
            "['c', '++', 'influenced', 'c', '.', 'main', 'difference', 'arises', 'oops', 'concept', 'inheritance', 'c', \"'\", 'support', 'inheritance', '.']\n",
            "\n",
            "Stemming: \n",
            "Hello  :  hello\n",
            "There  :  there\n",
            "!  :  !\n",
            "This  :  thi\n",
            "is  :  is\n",
            "Keerthana  :  keerthana\n",
            "here  :  here\n",
            "!  :  !\n",
            "Topic  :  topic\n",
            "is  :  is\n",
            "Programming  :  program\n",
            "using  :  use\n",
            "Python  :  python\n",
            "Python  :  python\n",
            "is  :  is\n",
            "a  :  a\n",
            "high  :  high\n",
            "level  :  level\n",
            "language  :  languag\n",
            "which  :  which\n",
            "is  :  is\n",
            "converted  :  convert\n",
            "to  :  to\n",
            "low  :  low\n",
            "level  :  level\n",
            "using  :  use\n",
            "an  :  an\n",
            "interpreter  :  interpret\n",
            ".  :  .\n",
            "There  :  there\n",
            "are  :  are\n",
            "many  :  mani\n",
            "built  :  built\n",
            "-  :  -\n",
            "in  :  in\n",
            "functions  :  function\n",
            "and  :  and\n",
            "packges  :  packg\n",
            "to  :  to\n",
            "implement  :  implement\n",
            "any"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  :  ani\n",
            "idea  :  idea\n",
            "through  :  through\n",
            "program  :  program\n",
            ".  :  .\n",
            "Also  :  also\n",
            ",  :  ,\n",
            "there  :  there\n",
            "are  :  are\n",
            "frameworks  :  framework\n",
            "like  :  like\n",
            "Django  :  django\n",
            "to  :  to\n",
            "create  :  creat\n",
            "web  :  web\n",
            "applications  :  applic\n",
            "using  :  use\n",
            "python  :  python\n",
            ".  :  .\n",
            "Python  :  python\n",
            "is  :  is\n",
            "also  :  also\n",
            "being  :  be\n",
            "used  :  use\n",
            "in  :  in\n",
            "Data  :  data\n",
            "Science  :  scienc\n",
            "field  :  field\n",
            "for  :  for\n",
            "Machine  :  machin\n",
            "Learning  :  learn\n",
            ",  :  ,\n",
            "Image  :  imag\n",
            "Processing  :  process\n",
            "and  :  and\n",
            "Natural  :  natur\n",
            "Language  :  languag\n",
            "Processing  :  process\n",
            ".  :  .\n",
            "Python  :  python\n",
            "is  :  is\n",
            "a  :  a\n",
            "dynamically  :  dynam\n",
            "types  :  type\n",
            "and  :  and\n",
            "garbage  :  garbag\n",
            "collecting  :  collect\n",
            "language  :  languag\n",
            ".  :  .\n",
            "It  :  it\n",
            "supports  :  support\n",
            "multiple  :  multipl\n",
            "programming  :  program\n",
            "paradigms  :  paradigm\n",
            "like  :  like\n",
            "object  :  object\n",
            "oriented  :  orient\n",
            ",  :  ,\n",
            "functional  :  function\n",
            "and  :  and\n",
            "structured  :  structur\n",
            "programming  :  program\n",
            ".  :  .\n",
            "Next  :  next\n",
            "topic  :  topic\n",
            "is  :  is\n",
            "Programming  :  program\n",
            "using  :  use\n",
            "C  :  c\n",
            "++  :  ++\n",
            "C  :  c\n",
            "++  :  ++\n",
            "is  :  is\n",
            "also  :  also\n",
            "a  :  a\n",
            "high  :  high\n",
            "level  :  level\n",
            "structured  :  structur\n",
            "language  :  languag\n",
            ".  :  .\n",
            "C  :  c\n",
            "++  :  ++\n",
            "is  :  is\n",
            "an  :  an\n",
            "object  :  object\n",
            "oriented  :  orient\n",
            "language  :  languag\n",
            "which  :  which\n",
            "means  :  mean\n",
            "that  :  that\n",
            "it  :  it\n",
            "follows  :  follow\n",
            "the  :  the\n",
            "OOPs  :  oop\n",
            "concepts  :  concept\n",
            "of  :  of\n",
            "data  :  data\n",
            "abstraction  :  abstract\n",
            ",  :  ,\n",
            "encapsulation  :  encapsul\n",
            ",  :  ,\n",
            "modularity  :  modular\n",
            ",  :  ,\n",
            "inheritance  :  inherit\n",
            "and  :  and\n",
            "polymorphism  :  polymorph\n",
            ".  :  .\n",
            "C  :  c\n",
            "++  :  ++\n",
            "also  :  also\n",
            "supports  :  support\n",
            "the  :  the\n",
            "concept  :  concept\n",
            "of  :  of\n",
            "pointers  :  pointer\n",
            ".  :  .\n",
            "Java  :  java\n",
            ",  :  ,\n",
            "is  :  is\n",
            "similar  :  similar\n",
            "to  :  to\n",
            "C  :  c\n",
            "++  :  ++\n",
            "but  :  but\n",
            "avoid  :  avoid\n",
            "the  :  the\n",
            "issue  :  issu\n",
            "of  :  of\n",
            "dreaded  :  dread\n",
            "diamond  :  diamond\n",
            "caused  :  caus\n",
            "by  :  by\n",
            "multiple  :  multipl\n",
            "inheritance  :  inherit\n",
            "in  :  in\n",
            "C  :  c\n",
            "++.  :  ++.\n",
            "So  :  so\n",
            ",  :  ,\n",
            "multiple  :  multipl\n",
            "inheritance  :  inherit\n",
            "is  :  is\n",
            "possible  :  possibl\n",
            "only  :  onli\n",
            "in  :  in\n",
            "C  :  c\n",
            "++.  :  ++.\n",
            "C  :  c\n",
            "++  :  ++\n",
            "is  :  is\n",
            "influenced  :  influenc\n",
            "by  :  by\n",
            "C  :  c\n",
            ".  :  .\n",
            "But  :  but\n",
            "the  :  the\n",
            "main  :  main\n",
            "difference  :  differ\n",
            "arises  :  aris\n",
            "in  :  in\n",
            "the  :  the\n",
            "OOPs  :  oop\n",
            "concept  :  concept\n",
            "of  :  of\n",
            "inheritance  :  inherit\n",
            "as  :  as\n",
            "C  :  c\n",
            "doesn  :  doesn\n",
            "'  :  '\n",
            "t  :  t\n",
            "support  :  support\n",
            "inheritance  :  inherit\n",
            ".  :  .\n",
            "\n",
            "Lemmatization: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello :  Hello\n",
            "There :  There\n",
            "! :  !\n",
            "This :  This\n",
            "is :  is\n",
            "Keerthana :  Keerthana\n",
            "here :  here\n",
            "! :  !\n",
            "Topic :  Topic\n",
            "is :  is\n",
            "Programming :  Programming\n",
            "using :  using\n",
            "Python :  Python\n",
            "Python :  Python\n",
            "is :  is\n",
            "a :  a\n",
            "high :  high\n",
            "level :  level\n",
            "language :  language\n",
            "which :  which\n",
            "is :  is\n",
            "converted :  converted\n",
            "to :  to\n",
            "low :  low\n",
            "level :  level\n",
            "using :  using\n",
            "an :  an\n",
            "interpreter :  interpreter\n",
            ". :  .\n",
            "There :  There\n",
            "are :  are\n",
            "many :  many\n",
            "built :  built\n",
            "- :  -\n",
            "in :  in\n",
            "functions :  function\n",
            "and :  and\n",
            "packges :  packges\n",
            "to :  to\n",
            "implement :  implement\n",
            "any :  any\n",
            "idea :  idea\n",
            "through :  through\n",
            "program :  program\n",
            ". :  .\n",
            "Also :  Also\n",
            ", :  ,\n",
            "there :  there\n",
            "are :  are\n",
            "frameworks :  framework\n",
            "like :  like\n",
            "Django :  Django\n",
            "to :  to\n",
            "create :  create\n",
            "web :  web\n",
            "applications :  application\n",
            "using :  using\n",
            "python :  python\n",
            ". :  .\n",
            "Python :  Python\n",
            "is :  is\n",
            "also :  also\n",
            "being :  being\n",
            "used :  used\n",
            "in :  in\n",
            "Data :  Data\n",
            "Science :  Science\n",
            "field :  field\n",
            "for :  for\n",
            "Machine :  Machine\n",
            "Learning :  Learning\n",
            ", :  ,\n",
            "Image :  Image\n",
            "Processing :  Processing\n",
            "and :  and\n",
            "Natural :  Natural\n",
            "Language :  Language\n",
            "Processing :  Processing\n",
            ". :  .\n",
            "Python :  Python\n",
            "is :  is\n",
            "a :  a\n",
            "dynamically :  dynamically\n",
            "types :  type\n",
            "and :  and\n",
            "garbage :  garbage\n",
            "collecting :  collecting\n",
            "language :  language\n",
            ". :  .\n",
            "It :  It\n",
            "supports :  support\n",
            "multiple :  multiple\n",
            "programming :  programming\n",
            "paradigms :  paradigm\n",
            "like :  like\n",
            "object :  object\n",
            "oriented :  oriented\n",
            ", :  ,\n",
            "functional :  functional\n",
            "and :  and\n",
            "structured :  structured\n",
            "programming :  programming\n",
            ". :  .\n",
            "Next :  Next\n",
            "topic :  topic\n",
            "is :  is\n",
            "Programming :  Programming\n",
            "using :  using\n",
            "C :  C\n",
            "++ :  ++\n",
            "C :  C\n",
            "++ :  ++\n",
            "is :  is\n",
            "also :  also\n",
            "a :  a\n",
            "high :  high\n",
            "level :  level\n",
            "structured :  structured\n",
            "language :  language\n",
            ". :  .\n",
            "C :  C\n",
            "++ :  ++\n",
            "is :  is\n",
            "an :  an\n",
            "object :  object\n",
            "oriented :  oriented\n",
            "language :  language\n",
            "which :  which\n",
            "means :  mean\n",
            "that :  that\n",
            "it :  it\n",
            "follows :  follows\n",
            "the :  the\n",
            "OOPs :  OOPs\n",
            "concepts :  concept\n",
            "of :  of\n",
            "data :  data\n",
            "abstraction :  abstraction\n",
            ", :  ,\n",
            "encapsulation :  encapsulation\n",
            ", :  ,\n",
            "modularity :  modularity\n",
            ", :  ,\n",
            "inheritance :  inheritance\n",
            "and :  and\n",
            "polymorphism :  polymorphism\n",
            ". :  .\n",
            "C :  C\n",
            "++ :  ++\n",
            "also :  also\n",
            "supports :  support\n",
            "the :  the\n",
            "concept :  concept\n",
            "of :  of\n",
            "pointers :  pointer\n",
            ". :  .\n",
            "Java :  Java\n",
            ", :  ,\n",
            "is :  is\n",
            "similar :  similar\n",
            "to :  to\n",
            "C :  C\n",
            "++ :  ++\n",
            "but :  but\n",
            "avoid :  avoid\n",
            "the :  the\n",
            "issue :  issue\n",
            "of :  of\n",
            "dreaded :  dreaded\n",
            "diamond :  diamond\n",
            "caused :  caused\n",
            "by :  by\n",
            "multiple :  multiple\n",
            "inheritance :  inheritance\n",
            "in :  in\n",
            "C :  C\n",
            "++. :  ++.\n",
            "So :  So\n",
            ", :  ,\n",
            "multiple :  multiple\n",
            "inheritance :  inheritance\n",
            "is :  is\n",
            "possible :  possible\n",
            "only :  only\n",
            "in :  in\n",
            "C :  C\n",
            "++. :  ++.\n",
            "C :  C\n",
            "++ :  ++\n",
            "is :  is\n",
            "influenced :  influenced\n",
            "by :  by\n",
            "C :  C\n",
            ". :  .\n",
            "But :  But\n",
            "the :  the\n",
            "main :  main\n",
            "difference :  difference\n",
            "arises :  arises\n",
            "in :  in\n",
            "the :  the\n",
            "OOPs :  OOPs\n",
            "concept :  concept\n",
            "of :  of\n",
            "inheritance :  inheritance\n",
            "as :  a\n",
            "C :  C\n",
            "doesn :  doesn\n",
            "' :  '\n",
            "t :  t\n",
            "support :  support\n",
            "inheritance :  inheritance\n",
            ". :  .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "POS tagger: \n",
            "[('hello', 'NN'), ('!', '.')]\n",
            "[('keerthana', 'NN'), ('!', '.')]\n",
            "[('topic', 'NN'), ('programming', 'VBG'), ('using', 'VBG'), ('python', 'JJ'), ('python', 'JJ'), ('high', 'JJ'), ('level', 'NN'), ('language', 'NN'), ('converted', 'VBD'), ('low', 'JJ'), ('level', 'NN'), ('using', 'VBG'), ('interpreter', 'NN'), ('.', '.')]\n",
            "[('many', 'JJ'), ('built', 'VBN'), ('-', ':'), ('functions', 'NNS'), ('packges', 'VBP'), ('implement', 'JJ'), ('idea', 'NN'), ('program', 'NN'), ('.', '.')]\n",
            "[('also', 'RB'), (',', ','), ('frameworks', 'NNS'), ('like', 'IN'), ('django', 'NN'), ('create', 'NN'), ('web', 'NN'), ('applications', 'NNS'), ('using', 'VBG'), ('python', 'NN'), ('.', '.')]\n",
            "[('python', 'NN'), ('also', 'RB'), ('used', 'VBD'), ('data', 'NNS'), ('science', 'NN'), ('field', 'NN'), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('image', 'NN'), ('processing', 'NN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('.', '.')]\n",
            "[('python', 'NN'), ('dynamically', 'RB'), ('types', 'VBZ'), ('garbage', 'NN'), ('collecting', 'VBG'), ('language', 'NN'), ('.', '.')]\n",
            "[('supports', 'NNS'), ('multiple', 'NN'), ('programming', 'VBG'), ('paradigms', 'NN'), ('like', 'IN'), ('object', 'NN'), ('oriented', 'VBN'), (',', ','), ('functional', 'JJ'), ('structured', 'VBD'), ('programming', 'NN'), ('.', '.')]\n",
            "[('next', 'JJ'), ('topic', 'NN'), ('programming', 'VBG'), ('using', 'VBG'), ('c', 'JJ'), ('++', 'NNP'), ('c', 'NN'), ('++', 'NNP'), ('also', 'RB'), ('high', 'JJ'), ('level', 'NN'), ('structured', 'VBD'), ('language', 'NN'), ('.', '.')]\n",
            "[('c', 'NNS'), ('++', 'VBP'), ('object', 'JJ'), ('oriented', 'VBN'), ('language', 'NN'), ('means', 'VBZ'), ('follows', 'VBZ'), ('oops', 'RP'), ('concepts', 'NNS'), ('data', 'NNS'), ('abstraction', 'NN'), (',', ','), ('encapsulation', 'NN'), (',', ','), ('modularity', 'NN'), (',', ','), ('inheritance', 'NN'), ('polymorphism', 'NN'), ('.', '.')]\n",
            "[('c', 'NN'), ('++', 'NNP'), ('also', 'RB'), ('supports', 'VBZ'), ('concept', 'NN'), ('pointers', 'NNS'), ('.', '.')]\n",
            "[('java', 'NN'), (',', ','), ('similar', 'JJ'), ('c', 'NN'), ('++', 'NNP'), ('avoid', 'VBZ'), ('issue', 'NN'), ('dreaded', 'VBD'), ('diamond', 'NN'), ('caused', 'VBN'), ('multiple', 'JJ'), ('inheritance', 'NN'), ('c', 'NN'), ('++', 'NN'), ('.', '.')]\n",
            "[(',', ','), ('multiple', 'JJ'), ('inheritance', 'NN'), ('possible', 'JJ'), ('c', 'NN'), ('++', 'NN'), ('.', '.')]\n",
            "[('c', 'NNS'), ('++', 'VBP'), ('influenced', 'JJ'), ('c', 'NN'), ('.', '.'), ('main', 'JJ'), ('difference', 'NN'), ('arises', 'NNS'), ('oops', 'VBP'), ('concept', 'JJ'), ('inheritance', 'NN'), ('c', 'NN'), (\"'\", \"''\"), ('support', 'NN'), ('inheritance', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    }
  ]
}